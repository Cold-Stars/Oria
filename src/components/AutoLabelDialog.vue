<script setup>
import { ref, computed, watch } from "vue";
import { invoke } from "@tauri-apps/api/core";
import { createDiscreteApi } from "naive-ui";

const { message } = createDiscreteApi(["message"]);

const emit = defineEmits(["close", "inference-complete"]);

const props = defineProps({
  visible: {
    type: Boolean,
    default: false,
  },
  currentImageIndex: {
    type: Number,
    default: 0,
  },
  totalImages: {
    type: Number,
    default: 0,
  },
  imageFiles: {
    type: Array,
    default: () => [],
  },
});

// æ¨ç†æ¨¡å¼: api æˆ– onnx
const inferenceMode = ref("api");

// APIé…ç½®
const apiConfig = ref({
  baseUrl: "http://localhost:8000",
  confThreshold: 0.25,
  iouThreshold: 0.45,
});

// ONNXé…ç½®
const onnxConfig = ref({
  modelPath: "",
  confThreshold: 0.25,
  iouThreshold: 0.45,
  useGpu: false,
});

// ONNXæ¨¡å‹çŠ¶æ€
const onnxModelStatus = ref(null); // null, 'loading', 'loaded', 'error'
const onnxModelMessage = ref("");
const onnxModelInfo = ref(null);

// æ¨ç†æ•°é‡é…ç½® - é»˜è®¤æ¨ç†å½“å‰åŠä¹‹åæ‰€æœ‰å›¾ç‰‡
const countMode = ref("all"); // å›ºå®šä¸º 'all'

// çŠ¶æ€
const isInferencing = ref(false);
const apiHealthStatus = ref(null); // null, 'checking', 'healthy', 'error'
const apiHealthMessage = ref("");
const modelInfo = ref(null);

// è¿›åº¦
const progress = ref(0);
const currentInferenceIndex = ref(0);

// è®¡ç®—å®é™…è¦æ¨ç†çš„æ•°é‡ - å§‹ç»ˆæ¨ç†å½“å‰åŠä¹‹åçš„æ‰€æœ‰å›¾ç‰‡
const actualCount = computed(() => {
  const remaining = props.totalImages - props.currentImageIndex;
  return remaining;
});

// æ¨ç†æŒ‰é’®æ–‡æœ¬
const inferenceButtonText = computed(() => {
  if (isInferencing.value) {
    return `æ¨ç†ä¸­... (${currentInferenceIndex.value}/${actualCount.value})`;
  }
  return `å¼€å§‹æ¨ç† (${actualCount.value}å¼ )`;
});

// æ£€æŸ¥APIå¥åº·çŠ¶æ€
const checkApiHealth = async () => {
  apiHealthStatus.value = "checking";
  apiHealthMessage.value = "æ­£åœ¨è¿æ¥...";

  try {
    const isHealthy = await invoke("check_api_health", {
      baseUrl: apiConfig.value.baseUrl,
    });

    if (isHealthy) {
      apiHealthStatus.value = "healthy";
      apiHealthMessage.value = "æœåŠ¡æ­£å¸¸";

      // è·å–æ¨¡å‹ä¿¡æ¯
      try {
        const info = await invoke("get_api_model_info", {
          baseUrl: apiConfig.value.baseUrl,
        });
        modelInfo.value = info;
      } catch (error) {
        console.error("è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥:", error);
      }
    } else {
      apiHealthStatus.value = "error";
      apiHealthMessage.value = "æœåŠ¡å¼‚å¸¸";
    }
  } catch (error) {
    console.error("å¥åº·æ£€æŸ¥å¤±è´¥:", error);
    apiHealthStatus.value = "error";
    apiHealthMessage.value = `è¿æ¥å¤±è´¥: ${error}`;
  }
};

// é˜²æŠ–å®šæ—¶å™¨
let healthCheckTimeout = null;

// å½“API URLå˜åŒ–æ—¶ï¼Œè‡ªåŠ¨æ£€æŸ¥å¥åº·çŠ¶æ€ï¼ˆé˜²æŠ–ï¼‰
watch(
  () => apiConfig.value.baseUrl,
  () => {
    if (props.visible && inferenceMode.value === "api" && !isInferencing.value) {
      // æ¸…é™¤ä¹‹å‰çš„å®šæ—¶å™¨
      if (healthCheckTimeout) {
        clearTimeout(healthCheckTimeout);
      }
      // å»¶è¿Ÿ500msæ‰§è¡Œï¼Œé¿å…é¢‘ç¹è°ƒç”¨
      healthCheckTimeout = setTimeout(() => {
        checkApiHealth();
      }, 500);
    }
  }
);

// å½“å¯¹è¯æ¡†æ‰“å¼€æ—¶ï¼Œæ£€æŸ¥APIå¥åº·çŠ¶æ€
watch(
  () => props.visible,
  (newVal, oldVal) => {
    console.log("å¯¹è¯æ¡†å¯è§æ€§å˜åŒ–:", oldVal, "=>", newVal);
    if (newVal && !oldVal && inferenceMode.value === "api" && !isInferencing.value) {
      // åªåœ¨ä»ä¸å¯è§å˜ä¸ºå¯è§æ—¶æ£€æŸ¥
      checkApiHealth();
    }
  }
);

// é€‰æ‹©ONNXæ¨¡å‹æ–‡ä»¶
const selectOnnxModel = async () => {
  try {
    const path = await invoke("select_onnx_model");
    onnxConfig.value.modelPath = path;

    // éªŒè¯æ¨¡å‹
    await validateOnnxModel();
  } catch (error) {
    if (
      !error.toString().includes("æœªé€‰æ‹©æ–‡ä»¶") &&
      !error.toString().includes("No file selected")
    ) {
      console.error("é€‰æ‹©æ¨¡å‹å¤±è´¥:", error);
      message.error(`é€‰æ‹©æ¨¡å‹å¤±è´¥: ${error}`);
    }
  }
};

// éªŒè¯ONNXæ¨¡å‹
const validateOnnxModel = async () => {
  if (!onnxConfig.value.modelPath) {
    return;
  }

  onnxModelStatus.value = "loading";
  onnxModelMessage.value = "æ­£åœ¨åŠ è½½æ¨¡å‹...";

  try {
    const info = await invoke("validate_onnx_model", {
      modelPath: onnxConfig.value.modelPath,
    });

    onnxModelStatus.value = "loaded";
    onnxModelMessage.value = "æ¨¡å‹åŠ è½½æˆåŠŸ";
    onnxModelInfo.value = info;
  } catch (error) {
    onnxModelStatus.value = "error";
    onnxModelMessage.value = `æ¨¡å‹åŠ è½½å¤±è´¥: ${error}`;
    onnxModelInfo.value = null;
  }
};

// å¼€å§‹æ¨ç†
const startInference = async () => {
  if (actualCount.value <= 0) {
    message.warning("æ²¡æœ‰å›¾ç‰‡å¯ä»¥æ¨ç†");
    return;
  }

  // æ£€æŸ¥æ¨ç†æ¨¡å¼çš„å¯ç”¨æ€§
  if (inferenceMode.value === "api") {
    if (apiHealthStatus.value !== "healthy") {
      message.error("APIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥è¿æ¥");
      return;
    }
  } else if (inferenceMode.value === "onnx") {
    if (onnxModelStatus.value !== "loaded") {
      message.error("ONNXæ¨¡å‹æœªåŠ è½½ï¼Œè¯·é€‰æ‹©å¹¶éªŒè¯æ¨¡å‹");
      return;
    }
  }

  isInferencing.value = true;
  progress.value = 0;
  currentInferenceIndex.value = 0;

  try {
    // æ„å»ºæ¨ç†é…ç½®
    const config = {
      mode:
        inferenceMode.value === "api"
          ? {
              type: "api",
              base_url: apiConfig.value.baseUrl,
              conf_threshold: apiConfig.value.confThreshold,
              iou_threshold: apiConfig.value.iouThreshold,
            }
          : {
              type: "onnx",
              model_path: onnxConfig.value.modelPath,
              conf_threshold: onnxConfig.value.confThreshold,
              iou_threshold: onnxConfig.value.iouThreshold,
              use_gpu: onnxConfig.value.useGpu,
            },
      count: {
        type: "count",
        value: actualCount.value,
      },
    };

    // è°ƒç”¨æ‰¹é‡æ¨ç†
    const result = await invoke("inference_batch", {
      imagePaths: props.imageFiles,
      startIndex: props.currentImageIndex,
      count: actualCount.value,
      config: config,
    });

    message.success(`æ¨ç†å®Œæˆï¼æˆåŠŸ: ${result.success_count}, å¤±è´¥: ${result.error_count}`);

    // é€šçŸ¥çˆ¶ç»„ä»¶åˆ·æ–°
    emit("inference-complete", result);

    // æ¨ç†æˆåŠŸåé‡ç½®çŠ¶æ€å¹¶å…³é—­å¯¹è¯æ¡†
    isInferencing.value = false;
    progress.value = 0;
    currentInferenceIndex.value = 0;
    emit("close");
  } catch (error) {
    console.error("æ¨ç†å¤±è´¥:", error);
    message.error(`æ¨ç†å¤±è´¥: ${error}`);

    // æ¨ç†å¤±è´¥åé‡ç½®çŠ¶æ€
    isInferencing.value = false;
    progress.value = 0;
    currentInferenceIndex.value = 0;

    // æ¨ç†å¤±è´¥åé‡æ–°æ£€æŸ¥APIå¥åº·çŠ¶æ€ï¼ˆä»…APIæ¨¡å¼ï¼Œä¸”å¯¹è¯æ¡†ä»æ‰“å¼€ï¼‰
    if (inferenceMode.value === "api" && props.visible) {
      checkApiHealth();
    }
  }
};

// å…³é—­å¯¹è¯æ¡†
const closeDialog = () => {
  if (!isInferencing.value) {
    emit("close");
  }
};
</script>

<template>
  <n-modal :show="visible" :mask-closable="!isInferencing" @update:show="closeDialog">
    <n-card
      style="width: 600px"
      title="æ¨¡å‹è‡ªåŠ¨æ ‡æ³¨"
      :bordered="false"
      size="huge"
      role="dialog"
      aria-modal="true"
    >
      <template #header-extra>
        <n-button text @click="closeDialog" :disabled="isInferencing" style="font-size: 20px">
          âœ•
        </n-button>
      </template>

      <n-space vertical :size="20">
        <!-- æ¨ç†æ¨¡å¼é€‰æ‹© -->
        <n-form-item label="æ¨ç†æ¨¡å¼">
          <n-radio-group v-model:value="inferenceMode" :disabled="isInferencing">
            <n-radio value="api"> APIæ¨ç† </n-radio>
            <n-radio value="onnx"> ONNXæ¨ç† </n-radio>
          </n-radio-group>
        </n-form-item>

        <!-- APIæ¨¡å¼é…ç½® -->
        <div v-if="inferenceMode === 'api'">
          <n-space vertical :size="12">
            <n-form-item label="APIåœ°å€">
              <n-input
                v-model:value="apiConfig.baseUrl"
                placeholder="http://localhost:8000"
                :disabled="isInferencing"
              />
            </n-form-item>

            <n-space align="center">
              <n-button
                size="small"
                @click="checkApiHealth"
                :loading="apiHealthStatus === 'checking'"
                :disabled="isInferencing"
              >
                æµ‹è¯•è¿æ¥
              </n-button>
              <n-tag v-if="apiHealthStatus === 'healthy'" type="success" size="small">
                {{ apiHealthMessage }}
              </n-tag>
              <n-tag v-else-if="apiHealthStatus === 'error'" type="error" size="small">
                {{ apiHealthMessage }}
              </n-tag>
              <n-tag v-else-if="apiHealthStatus === 'checking'" size="small">
                {{ apiHealthMessage }}
              </n-tag>
            </n-space>

            <!-- æ¨¡å‹ä¿¡æ¯ -->
            <div v-if="modelInfo" class="model-info">
              <n-text depth="3" style="font-size: 12px">
                æ¨¡å‹: {{ modelInfo.model_name }} | ç±»åˆ«æ•°: {{ modelInfo.class_names.length }} |
                è¾“å…¥å°ºå¯¸:
                {{ modelInfo.input_size.join("x") }}
              </n-text>
            </div>

            <n-form-item label="ç½®ä¿¡åº¦é˜ˆå€¼">
              <n-slider
                v-model:value="apiConfig.confThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                :disabled="isInferencing"
              />
              <n-input-number
                v-model:value="apiConfig.confThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                style="margin-left: 12px; width: 130px"
                :disabled="isInferencing"
              />
            </n-form-item>

            <n-form-item label="IOUé˜ˆå€¼">
              <n-slider
                v-model:value="apiConfig.iouThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                :disabled="isInferencing"
              />
              <n-input-number
                v-model:value="apiConfig.iouThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                style="margin-left: 12px; width: 130px"
                :disabled="isInferencing"
              />
            </n-form-item>
          </n-space>
        </div>

        <!-- ONNXæ¨¡å¼é…ç½® -->
        <div v-if="inferenceMode === 'onnx'">
          <n-space vertical :size="12">
            <n-form-item label="æ¨¡å‹æ–‡ä»¶">
              <n-space style="width: 100%">
                <n-input
                  v-model:value="onnxConfig.modelPath"
                  placeholder="é€‰æ‹©ONNXæ¨¡å‹æ–‡ä»¶ (.onnx)"
                  :disabled="isInferencing"
                  readonly
                  style="flex: 1"
                />
                <n-button @click="selectOnnxModel" :disabled="isInferencing"> é€‰æ‹©æ¨¡å‹ </n-button>
              </n-space>
            </n-form-item>

            <n-space align="center" v-if="onnxConfig.modelPath">
              <n-button
                size="small"
                @click="validateOnnxModel"
                :loading="onnxModelStatus === 'loading'"
                :disabled="isInferencing"
              >
                éªŒè¯æ¨¡å‹
              </n-button>
              <n-tag v-if="onnxModelStatus === 'loaded'" type="success" size="small">
                {{ onnxModelMessage }}
              </n-tag>
              <n-tag v-else-if="onnxModelStatus === 'error'" type="error" size="small">
                {{ onnxModelMessage }}
              </n-tag>
              <n-tag v-else-if="onnxModelStatus === 'loading'" size="small">
                {{ onnxModelMessage }}
              </n-tag>
            </n-space>

            <!-- æ¨¡å‹ä¿¡æ¯ -->
            <div v-if="onnxModelInfo" class="model-info">
              <n-text depth="3" style="font-size: 12px">
                ç±»åˆ«æ•°: {{ onnxModelInfo.class_names.length }} | è¾“å…¥å°ºå¯¸:
                {{ onnxModelInfo.input_size.join("x") }}
              </n-text>
            </div>

            <n-alert v-if="!onnxConfig.modelPath" type="info" title="æç¤º">
              è¯·é€‰æ‹©ä¸€ä¸ªONNXæ ¼å¼çš„YOLOv8æ¨¡å‹æ–‡ä»¶
            </n-alert>

            <n-form-item label="ç½®ä¿¡åº¦é˜ˆå€¼">
              <n-slider
                v-model:value="onnxConfig.confThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                :disabled="isInferencing"
              />
              <n-input-number
                v-model:value="onnxConfig.confThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                style="margin-left: 12px; width: 120px"
                :disabled="isInferencing"
              />
            </n-form-item>

            <n-form-item label="IOUé˜ˆå€¼">
              <n-slider
                v-model:value="onnxConfig.iouThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                :disabled="isInferencing"
              />
              <n-input-number
                v-model:value="onnxConfig.iouThreshold"
                :step="0.05"
                :min="0.1"
                :max="0.9"
                style="margin-left: 12px; width: 120px"
                :disabled="isInferencing"
              />
            </n-form-item>

            <n-form-item label="ä½¿ç”¨GPUåŠ é€Ÿ">
              <n-space align="center">
                <n-switch v-model:value="onnxConfig.useGpu" :disabled="isInferencing" />
                <n-text depth="3" style="font-size: 12px">
                  {{ onnxConfig.useGpu ? "GPU (CUDA)" : "CPU" }}
                </n-text>
              </n-space>
              <n-text depth="3" style="font-size: 11px; margin-top: 4px">
                æ³¨æ„: GPUæ¨ç†éœ€è¦å®‰è£…CUDAå’Œå¯¹åº”çš„ONNX Runtime GPUç‰ˆæœ¬
              </n-text>
            </n-form-item>
          </n-space>
        </div>

        <n-divider />

        <!-- æ¨ç†æ•°é‡ä¿¡æ¯ -->
        <n-alert type="info" :bordered="false">
          <template #icon>
            <span style="font-size: 16px">ğŸ“Š</span>
          </template>
          <div style="line-height: 1.6">
            <div>
              å°†ä»ç¬¬ <n-text strong>{{ currentImageIndex + 1 }}</n-text> å¼ å›¾ç‰‡å¼€å§‹æ¨ç†
            </div>
            <div style="margin-top: 4px">
              å…±æ¨ç† <n-text strong type="primary">{{ actualCount }}</n-text> å¼ å›¾ç‰‡
              <n-text depth="3" style="font-size: 12px"> ï¼ˆå½“å‰åŠä¹‹åçš„æ‰€æœ‰å›¾ç‰‡ï¼‰ </n-text>
            </div>
          </div>
        </n-alert>

        <!-- è¿›åº¦æ¡ -->
        <div v-if="isInferencing">
          <n-progress type="line" :percentage="progress" :indicator-placement="'inside'" />
          <n-text depth="3" style="font-size: 12px; margin-top: 8px">
            æ­£åœ¨æ¨ç†: {{ currentInferenceIndex }} / {{ actualCount }}
          </n-text>
        </div>
      </n-space>

      <template #footer>
        <n-space justify="end">
          <n-button @click="closeDialog" :disabled="isInferencing"> å–æ¶ˆ </n-button>
          <n-button
            type="primary"
            @click="startInference"
            :disabled="
              isInferencing ||
              (inferenceMode === 'api' && apiHealthStatus !== 'healthy') ||
              (inferenceMode === 'onnx' && onnxModelStatus !== 'loaded') ||
              actualCount <= 0
            "
            :loading="isInferencing"
          >
            {{ inferenceButtonText }}
          </n-button>
        </n-space>
      </template>
    </n-card>
  </n-modal>
</template>

<style scoped>
.model-info {
  padding: 8px 12px;
  background-color: #f5f5f5;
  border-radius: 4px;
  margin-top: 8px;
}
</style>
