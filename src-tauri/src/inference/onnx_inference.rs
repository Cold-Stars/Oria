/// ONNXæ¨ç†æ¨¡å—
/// åŸºäºYOLOv8-ONNXRuntime-Rustç®€åŒ–å®ç°
use anyhow::{Context, Result};
use image::{DynamicImage, GenericImageView};
use ndarray::{s, Array, ArrayView, Axis, CowArray, IxDyn};
use ort::{Environment, ExecutionProvider, GraphOptimizationLevel, Session, SessionBuilder, Value};
use std::sync::Arc;

use super::api_client::Detection;

/// ONNXæ¨ç†å™¨
pub struct OnnxInferenceEngine {
    session: Arc<std::sync::Mutex<Session>>,
    #[allow(dead_code)]
    environment: Arc<Environment>,
    input_width: u32,
    input_height: u32,
    conf_threshold: f32,
    iou_threshold: f32,
    class_names: Vec<String>,
    #[allow(dead_code)]
    use_gpu: bool,
}

impl OnnxInferenceEngine {
    /// åˆ›å»ºæ–°çš„ONNXæ¨ç†å™¨
    pub fn new(
        model_path: &str,
        conf_threshold: f32,
        iou_threshold: f32,
        use_gpu: bool,
    ) -> Result<Self> {
        // åˆ›å»ºONNX Runtimeç¯å¢ƒï¼Œæ ¹æ®å‚æ•°é€‰æ‹©æ‰§è¡Œæä¾›è€…
        let execution_providers = if use_gpu {
            // println!("å°è¯•ä½¿ç”¨ GPU åŠ é€Ÿ (CUDA)");
            vec![
                ExecutionProvider::CUDA(Default::default()),
                ExecutionProvider::CPU(Default::default()),
            ]
        } else {
            // println!("ä½¿ç”¨ CPU æ¨ç†");
            vec![ExecutionProvider::CPU(Default::default())]
        };

        let environment = Arc::new(
            Environment::builder()
                .with_name("yolov8")
                .with_execution_providers(execution_providers)
                .build()
                .context("æ— æ³•åˆ›å»ºONNX Runtimeç¯å¢ƒ")?,
        );

        // åŠ è½½ONNXæ¨¡å‹
        let session = SessionBuilder::new(&environment)?
            .with_optimization_level(GraphOptimizationLevel::Level1)?
            .with_intra_threads(4)?
            .with_model_from_file(model_path)
            .context("æ— æ³•åŠ è½½ONNXæ¨¡å‹")?;

        // æ£€æŸ¥å®é™…ä½¿ç”¨çš„æ‰§è¡Œæä¾›è€…
        // println!("âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸï¼");

        // è·å–è¾“å…¥å°ºå¯¸ - ä»è¾“å…¥å½¢çŠ¶è·å–
        let input_shape = session.inputs[0].dimensions().collect::<Vec<_>>();
        let input_height = input_shape
            .get(2)
            .and_then(|d| d.map(|v| v as u32))
            .unwrap_or(640);
        let input_width = input_shape
            .get(3)
            .and_then(|d| d.map(|v| v as u32))
            .unwrap_or(640);

        // å°è¯•ä»å…ƒæ•°æ®è·å–ç±»åˆ«åç§°
        let class_names = Self::get_class_names_from_metadata(&session);

        Ok(Self {
            session: Arc::new(std::sync::Mutex::new(session)),
            environment,
            input_width,
            input_height,
            conf_threshold,
            iou_threshold,
            class_names,
            use_gpu,
        })
    }

    /// ä»æ¨¡å‹å…ƒæ•°æ®è·å–ç±»åˆ«åç§° (é™æ€æ–¹æ³•)
    fn get_class_names_from_metadata(session: &Session) -> Vec<String> {
        // å°è¯•ä»å…ƒæ•°æ®è¯»å–ç±»åˆ«åç§°
        if let Ok(metadata) = session.metadata() {
            if let Ok(Some(names_str)) = metadata.custom("names") {
                // è§£ææ ¼å¼: {0: 'person', 1: 'bicycle', ...}
                let re = regex::Regex::new(r#"['"]([^'"]+)['"]"#).unwrap();
                let names: Vec<String> = re
                    .captures_iter(names_str.as_ref())
                    .map(|cap| cap[1].to_string())
                    .collect();
                if !names.is_empty() {
                    return names;
                }
            }
        }

        // é»˜è®¤ä½¿ç”¨COCOç±»åˆ«
        vec![
            "person",
            "bicycle",
            "car",
            "motorcycle",
            "airplane",
            "bus",
            "train",
            "truck",
            "boat",
            "traffic light",
            "fire hydrant",
            "stop sign",
            "parking meter",
            "bench",
            "bird",
            "cat",
            "dog",
            "horse",
            "sheep",
            "cow",
            "elephant",
            "bear",
            "zebra",
            "giraffe",
            "backpack",
            "umbrella",
            "handbag",
            "tie",
            "suitcase",
            "frisbee",
            "skis",
            "snowboard",
            "sports ball",
            "kite",
            "baseball bat",
            "baseball glove",
            "skateboard",
            "surfboard",
            "tennis racket",
            "bottle",
            "wine glass",
            "cup",
            "fork",
            "knife",
            "spoon",
            "bowl",
            "banana",
            "apple",
            "sandwich",
            "orange",
            "broccoli",
            "carrot",
            "hot dog",
            "pizza",
            "donut",
            "cake",
            "chair",
            "couch",
            "potted plant",
            "bed",
            "dining table",
            "toilet",
            "tv",
            "laptop",
            "mouse",
            "remote",
            "keyboard",
            "cell phone",
            "microwave",
            "oven",
            "toaster",
            "sink",
            "refrigerator",
            "book",
            "clock",
            "vase",
            "scissors",
            "teddy bear",
            "hair drier",
            "toothbrush",
        ]
        .iter()
        .map(|s| s.to_string())
        .collect()
    }

    /// æ¨ç†å•å¼ å›¾ç‰‡
    pub fn inference(&self, image: &DynamicImage) -> Result<Vec<Detection>> {
        let start_time = std::time::Instant::now();

        // println!(
        //     "ğŸš€ å¼€å§‹æ¨ç† [è®¾å¤‡: {}]",
        //     if self.use_gpu { "GPU (CUDA)" } else { "CPU" }
        // );

        // é¢„å¤„ç†
        let preprocess_start = std::time::Instant::now();
        let (preprocessed, ratio, padding) = self.preprocess(image)?;
        let _preprocess_time = preprocess_start.elapsed().as_secs_f32() * 1000.0;

        // æ¨ç† - åˆ›å»º Value
        let inference_start = std::time::Instant::now();
        let session_lock = self.session.lock().unwrap();
        let allocator = session_lock.allocator();

        // è½¬æ¢ä¸º CowArray ç”¨äºåˆ›å»º Value
        let array_view: ArrayView<f32, IxDyn> = preprocessed.view();
        let cow_array: CowArray<f32, IxDyn> = CowArray::from(array_view);
        let input_tensor = Value::from_array(allocator, &cow_array)?;

        let outputs = session_lock
            .run(vec![input_tensor])
            .context("ONNXæ¨ç†å¤±è´¥")?;
        let _inference_time = inference_start.elapsed().as_secs_f32() * 1000.0;

        // åå¤„ç†
        let postprocess_start = std::time::Instant::now();
        let detections = self.postprocess(&outputs, image, ratio, padding)?;
        let _postprocess_time = postprocess_start.elapsed().as_secs_f32() * 1000.0;

        let _total_time = start_time.elapsed().as_secs_f32() * 1000.0;

        // println!(
        //     "â±ï¸  æ¨ç†æ€§èƒ½ç»Ÿè®¡:\n   é¢„å¤„ç†: {:.2}ms | æ¨¡å‹æ¨ç†: {:.2}ms | åå¤„ç†: {:.2}ms | æ€»è®¡: {:.2}ms",
        //     preprocess_time, inference_time, postprocess_time, total_time
        // );

        Ok(detections)
    }

    /// å›¾ç‰‡é¢„å¤„ç†
    /// è¿”å›ï¼š(é¢„å¤„ç†åçš„æ•°ç»„, ç¼©æ”¾æ¯”ä¾‹, (padding_left, padding_top))
    fn preprocess(&self, image: &DynamicImage) -> Result<(Array<f32, IxDyn>, f32, (f32, f32))> {
        let (img_width, img_height) = image.dimensions();
        let img_width = img_width as f32;
        let img_height = img_height as f32;

        // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
        let ratio =
            (self.input_width as f32 / img_width).min(self.input_height as f32 / img_height);

        let new_width = (img_width * ratio).round() as u32;
        let new_height = (img_height * ratio).round() as u32;

        // è®¡ç®—paddingï¼ˆä¸Python letterboxä¿æŒä¸€è‡´ï¼‰
        let dw = (self.input_width as f32 - new_width as f32) / 2.0;
        let dh = (self.input_height as f32 - new_height as f32) / 2.0;

        // Pythonä»£ç ä¸­çš„paddingè®¡ç®—ï¼štop, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        let pad_left = (dw - 0.1).round() as usize;
        let pad_top = (dh - 0.1).round() as usize;

        // ç¼©æ”¾å›¾ç‰‡
        let resized =
            image.resize_exact(new_width, new_height, image::imageops::FilterType::Triangle);

        // åˆ›å»ºå¡«å……åçš„æ•°ç»„ (1, 3, H, W)ï¼Œå¡«å……å€¼ä¸º 114/255
        let mut input_array =
            Array::ones((1, 3, self.input_height as usize, self.input_width as usize)).into_dyn();
        input_array.fill(114.0 / 255.0);

        // å°†ç¼©æ”¾åçš„å›¾ç‰‡å¤åˆ¶åˆ°æ•°ç»„ä¸­ï¼ˆå½’ä¸€åŒ–åˆ°[0,1]ï¼‰ï¼Œè€ƒè™‘padding
        for (x, y, pixel) in resized.to_rgb8().enumerate_pixels() {
            let x = x as usize + pad_left;
            let y = y as usize + pad_top;
            input_array[[0, 0, y, x]] = pixel[0] as f32 / 255.0;
            input_array[[0, 1, y, x]] = pixel[1] as f32 / 255.0;
            input_array[[0, 2, y, x]] = pixel[2] as f32 / 255.0;
        }

        Ok((input_array, ratio, (dw, dh)))
    }

    /// åå¤„ç†æ¨ç†ç»“æœ
    fn postprocess(
        &self,
        outputs: &[Value],
        original_image: &DynamicImage,
        ratio: f32,
        padding: (f32, f32),
    ) -> Result<Vec<Detection>> {
        // è·å–è¾“å‡ºå¼ é‡
        let output_tensor = outputs[0]
            .try_extract::<f32>()
            .context("æ— æ³•æå–è¾“å‡ºå¼ é‡")?;

        let tensor_view = output_tensor.view();
        let shape = tensor_view.shape();
        let data = tensor_view.as_slice().context("æ— æ³•è·å–è¾“å‡ºæ•°æ®")?;

        // å°†æ•°æ®è½¬æ¢ä¸ºndarray
        let output = Array::from_shape_vec((shape[0], shape[1], shape[2]), data.to_vec())?;

        let (img_width, img_height) = original_image.dimensions();
        let mut detections = Vec::new();

        // output shape: (1, num_features, num_anchors)
        // ç§»é™¤batchç»´åº¦
        let output = output.index_axis_move(Axis(0), 0); // shape: (num_features, num_anchors)

        // åˆ¤æ–­æ˜¯å¦æ˜¯æ—‹è½¬æ¡†æ¨¡å‹
        // æ™®é€šæ¡†: num_features = 4 + num_classes (e.g., 84 for COCO)
        // æ—‹è½¬æ¡†: num_features = 4 + num_classes + 1 (æœ€åä¸€ç»´æ˜¯è§’åº¦)
        let num_features = output.shape()[0];
        let num_classes = self.class_names.len();
        let is_rotated = num_features == (4 + num_classes + 1);

        // è½¬ç½®ä¸º (num_anchors, num_features)
        let output = output.t();

        // éå†æ¯ä¸ªanchor
        for row in output.axis_iter(Axis(0)) {
            // å‰4ä¸ªæ˜¯bboxåæ ‡ (cx, cy, w, h)
            let cx: f32 = row[0];
            let cy: f32 = row[1];
            let w: f32 = row[2];
            let h: f32 = row[3];

            // æå–ç±»åˆ«ç½®ä¿¡åº¦
            let class_scores = if is_rotated {
                // æ—‹è½¬æ¡†: [cx, cy, w, h, class0, class1, ..., classN, angle]
                row.slice(s![4..(4 + num_classes)])
            } else {
                // æ™®é€šæ¡†: [cx, cy, w, h, class0, class1, ..., classN]
                row.slice(s![4..])
            };

            // æ‰¾åˆ°æœ€å¤§ç½®ä¿¡åº¦å’Œå¯¹åº”çš„ç±»åˆ«
            let (class_id, &confidence) = class_scores
                .iter()
                .enumerate()
                .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
                .unwrap();

            // ç½®ä¿¡åº¦è¿‡æ»¤
            if confidence < self.conf_threshold {
                continue;
            }

            // æå–è§’åº¦ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯æ—‹è½¬æ¡†ï¼‰
            let angle = if is_rotated {
                let mut angle_rad = row[num_features - 1]; // æœ€åä¸€ç»´æ˜¯è§’åº¦(å¼§åº¦)

                // è§’åº¦èŒƒå›´å¤„ç†ï¼Œå‚è€ƒPythonå®ç°
                // if 0.5 * math.pi <= angle <= 0.75 * math.pi: angle -= math.pi
                let pi = std::f32::consts::PI;
                if angle_rad >= 0.5 * pi && angle_rad <= 0.75 * pi {
                    angle_rad -= pi;
                }

                // è½¬æ¢ä¸ºåº¦ï¼ˆå»æ‰ä¹‹å‰çš„è´Ÿå·ï¼Œå› ä¸ºå…³äºyè½´å¯¹ç§°ï¼‰
                let mut angle_deg = angle_rad * 180.0 / pi;

                // ç¡®ä¿è§’åº¦ä¸ºéè´Ÿå€¼ï¼Œå°†è´Ÿå€¼è½¬æ¢ä¸º [0, 360) èŒƒå›´
                if angle_deg < 0.0 {
                    angle_deg += 360.0;
                }

                Some(angle_deg)
            } else {
                None
            };

            // åæ ‡è½¬æ¢ï¼šä»æ¨¡å‹è¾“å‡ºç©ºé—´è½¬æ¢åˆ°åŸå›¾ç©ºé—´
            // å‚è€ƒPythonçš„scale_boxeså‡½æ•°ï¼šå…ˆå‡paddingï¼Œå†é™¤ä»¥ratio
            let (pad_w, pad_h) = padding;
            let cx_img = (cx - pad_w) / ratio;
            let cy_img = (cy - pad_h) / ratio;
            let w_img = w / ratio;
            let h_img = h / ratio;

            // è·å–ç±»åˆ«åç§°
            let class_name = self
                .class_names
                .get(class_id)
                .cloned()
                .unwrap_or_else(|| format!("class_{}", class_id));

            if is_rotated {
                // æ—‹è½¬æ¡†ï¼šbboxä¿æŒä¸º[cx, cy, w, h]æ ¼å¼ï¼Œç”¨äºåç»­ç»˜åˆ¶æ—‹è½¬çŸ©å½¢
                detections.push(Detection {
                    class_id,
                    class_name,
                    confidence,
                    bbox: vec![cx_img, cy_img, w_img, h_img],
                    angle,
                });
            } else {
                // æ™®é€šæ¡†ï¼šè½¬æ¢ä¸º[x_min, y_min, x_max, y_max]æ ¼å¼
                // æ³¨æ„ï¼šæ™®é€šæ¡†ä¹Ÿéœ€è¦å‡å»padding
                let x_min_raw = cx - w / 2.0;
                let y_min_raw = cy - h / 2.0;
                let x_max_raw = cx + w / 2.0;
                let y_max_raw = cy + h / 2.0;

                let (pad_w, pad_h) = padding;
                let x_min = ((x_min_raw - pad_w) / ratio).max(0.0).min(img_width as f32);
                let y_min = ((y_min_raw - pad_h) / ratio)
                    .max(0.0)
                    .min(img_height as f32);
                let x_max = ((x_max_raw - pad_w) / ratio).max(0.0).min(img_width as f32);
                let y_max = ((y_max_raw - pad_h) / ratio)
                    .max(0.0)
                    .min(img_height as f32);

                detections.push(Detection {
                    class_id,
                    class_name,
                    confidence,
                    bbox: vec![x_min, y_min, x_max, y_max],
                    angle: None,
                });
            }
        }

        // NMS (éæå¤§å€¼æŠ‘åˆ¶)
        let detections = self.non_max_suppression(detections);

        Ok(detections)
    }

    /// éæå¤§å€¼æŠ‘åˆ¶ (NMS)
    fn non_max_suppression(&self, mut detections: Vec<Detection>) -> Vec<Detection> {
        // æŒ‰ç½®ä¿¡åº¦æ’åº
        detections.sort_by(|a, b| {
            b.confidence
                .partial_cmp(&a.confidence)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        let mut keep = Vec::new();

        while !detections.is_empty() {
            let current = detections.remove(0);
            keep.push(current.clone());

            detections.retain(|det| {
                // åªå¯¹åŒä¸€ç±»åˆ«è¿›è¡ŒNMS
                if det.class_id != current.class_id {
                    return true;
                }

                // è®¡ç®—IOU
                let iou = Self::calculate_iou(&current.bbox, &det.bbox, current.angle.is_some());
                iou < self.iou_threshold
            });
        }

        keep
    }

    /// è®¡ç®—ä¸¤ä¸ªbboxçš„IOU
    /// is_rotated: å¦‚æœä¸ºtrueï¼Œbboxæ ¼å¼ä¸º[cx, cy, w, h]ï¼›å¦åˆ™ä¸º[x_min, y_min, x_max, y_max]
    fn calculate_iou(box1: &[f32], box2: &[f32], is_rotated: bool) -> f32 {
        let (x1_min, y1_min, x1_max, y1_max) = if is_rotated {
            // ä»[cx, cy, w, h]è½¬æ¢ä¸º[x_min, y_min, x_max, y_max]
            let cx = box1[0];
            let cy = box1[1];
            let w = box1[2];
            let h = box1[3];
            (cx - w / 2.0, cy - h / 2.0, cx + w / 2.0, cy + h / 2.0)
        } else {
            (box1[0], box1[1], box1[2], box1[3])
        };

        let (x2_min, y2_min, x2_max, y2_max) = if is_rotated {
            // ä»[cx, cy, w, h]è½¬æ¢ä¸º[x_min, y_min, x_max, y_max]
            let cx = box2[0];
            let cy = box2[1];
            let w = box2[2];
            let h = box2[3];
            (cx - w / 2.0, cy - h / 2.0, cx + w / 2.0, cy + h / 2.0)
        } else {
            (box2[0], box2[1], box2[2], box2[3])
        };

        // è®¡ç®—äº¤é›†
        let inter_x_min = x1_min.max(x2_min);
        let inter_y_min = y1_min.max(y2_min);
        let inter_x_max = x1_max.min(x2_max);
        let inter_y_max = y1_max.min(y2_max);

        let inter_width = (inter_x_max - inter_x_min).max(0.0);
        let inter_height = (inter_y_max - inter_y_min).max(0.0);
        let inter_area = inter_width * inter_height;

        // è®¡ç®—å¹¶é›†
        let box1_area = (x1_max - x1_min) * (y1_max - y1_min);
        let box2_area = (x2_max - x2_min) * (y2_max - y2_min);
        let union_area = box1_area + box2_area - inter_area;

        if union_area > 0.0 {
            inter_area / union_area
        } else {
            0.0
        }
    }

    /// è·å–ç±»åˆ«åç§°åˆ—è¡¨
    pub fn get_class_names(&self) -> &[String] {
        &self.class_names
    }

    /// è·å–è¾“å…¥å°ºå¯¸
    pub fn get_input_size(&self) -> (u32, u32) {
        (self.input_width, self.input_height)
    }
}
